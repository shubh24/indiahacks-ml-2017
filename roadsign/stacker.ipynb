{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./new/train.csv\")\n",
    "test = pd.read_csv(\"./new/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clean label columns\n",
    "label = train.pop(\"Target\")\n",
    "test_ids = test.pop(\"Id\")\n",
    "\n",
    "#drop columns\n",
    "train.drop(['Id', 'DetectedCamera'], inplace=True, axis=1)\n",
    "test.drop(['DetectedCamera'], inplace=True,axis=1)\n",
    "\n",
    "#Validation split\n",
    "x_train, x_valid, label_train, label_valid = train_test_split(train, label, test_size=0.2, random_state=4242, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_xgb(x_train, label_train, x_valid = None, label_valid = None):\n",
    "\n",
    "    # Set our parameters for xgboost\n",
    "    params = {}\n",
    "    params['objective'] = 'multi:softprob'\n",
    "    params['eval_metric'] = 'mlogloss'\n",
    "    params['eta'] = 0.02\n",
    "    params['num_class'] = 4\n",
    "    params['max_depth'] = 4\n",
    "    params['silent'] = 1\n",
    "    params['min_child_weight'] = 0\n",
    "    params['subsample'] = 0.8\n",
    "    params['colsample_bytree'] = 0.8\n",
    "    params['nthread'] = 13\n",
    "\n",
    "    d_train = xgb.DMatrix(x_train, label=label_train)\n",
    "    \n",
    "    if x_valid is not None:\n",
    "        d_valid = xgb.DMatrix(x_valid, label=label_valid)\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'validation')]\n",
    "    else:\n",
    "        watchlist = [(d_train, 'train')]\n",
    "        \n",
    "    bst = xgb.train(params, d_train, 500, watchlist, early_stopping_rounds=50, verbose_eval=50)\n",
    "    \n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_xgb(func_train, func_label, func_test, k_fold_flag = 1):\n",
    "\n",
    "#     Validate\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    skf.get_n_splits(func_train, func_label)\n",
    "    \n",
    "    train_pred = pd.DataFrame()\n",
    "    \n",
    "    if k_fold_flag == 1:\n",
    "        for train_index, test_index in skf.split(func_train, func_label):\n",
    "\n",
    "            print test_index\n",
    "\n",
    "            kfold_train = func_train.iloc[train_index]\n",
    "            kfold_label = func_label.iloc[train_index]\n",
    "            kfold_test = func_train.iloc[test_index]\n",
    "\n",
    "            xgb_model = run_xgb(kfold_train, kfold_label)\n",
    "            kfold_pred = xgb_model.predict(xgb.DMatrix(kfold_test))\n",
    "            kfold_pred = pd.DataFrame(kfold_pred)\n",
    "            kfold_pred.columns = [\"xgb_zero\", \"xgb_one\", \"xgb_two\", \"xgb_three\"]\n",
    "\n",
    "            train_pred = pd.concat([train_pred, kfold_pred], axis = 0)\n",
    "\n",
    "        bst = run_xgb(func_train, func_label)    \n",
    "        d_val = xgb.DMatrix(func_test)\n",
    "        test_pred = bst.predict(d_val)\n",
    "\n",
    "        return train_pred, test_pred\n",
    "    else:\n",
    "        \n",
    "        bst = run_xgb(func_train, func_label)    \n",
    "        d_val = xgb.DMatrix(func_test)\n",
    "        test_pred = bst.predict(d_val)\n",
    "\n",
    "        return test_pred\n",
    "        \n",
    "#     Test\n",
    "#     bst = run_xgb(train, label)\n",
    "    \n",
    "#     d_train = xgb.DMatrix(train)\n",
    "#     d_test = xgb.DMatrix(test)\n",
    "    \n",
    "#     train_pred = bst.predict(d_train)\n",
    "#     test_pred = bst.predict(d_test)\n",
    "\n",
    "#     return train_pred, test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_gbm(x_train, label_train, x_valid = None, label_valid = None):\n",
    "\n",
    "    gbm = GradientBoostingClassifier(n_estimators=500, max_depth=5, learning_rate=0.05, random_state=10)\n",
    "    gbm.fit(x_train, label_train)\n",
    "    \n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_gbm(func_train, func_label, func_test, k_fold_flag = 1):\n",
    "    \n",
    "#     #Validation\n",
    "    \n",
    "    if k_fold_flag == 1:\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        skf.get_n_splits(func_train, func_label)\n",
    "\n",
    "        train_pred = pd.DataFrame()\n",
    "        for train_index, test_index in skf.split(func_train, func_label):\n",
    "\n",
    "            print test_index\n",
    "\n",
    "            kfold_train = func_train.iloc[train_index]\n",
    "            kfold_label = func_label.iloc[train_index]\n",
    "            kfold_test = func_train.iloc[test_index]\n",
    "\n",
    "            gbm_model = run_gbm(kfold_train, kfold_label)\n",
    "            kfold_pred = gbm_model.predict_proba(kfold_test)\n",
    "            kfold_pred = pd.DataFrame(kfold_pred)\n",
    "            kfold_pred.columns = [\"gbm_zero\", \"gbm_one\", \"gbm_two\", \"gbm_three\"]\n",
    "\n",
    "            train_pred = pd.concat([train_pred, kfold_pred], axis = 0)\n",
    "\n",
    "        gbm_model = run_gbm(func_train, func_label)\n",
    "        test_pred = gbm_model.predict_proba(func_test)\n",
    "\n",
    "        return train_pred, test_pred\n",
    "    \n",
    "    else:\n",
    "        gbm_model = run_gbm(func_train, func_label)\n",
    "        test_pred = gbm_model.predict_proba(func_test)\n",
    "        return test_pred\n",
    "        \n",
    "#     Testing\n",
    "#     gbm_model = run_gbm(train, label)\n",
    "    \n",
    "#     train_pred = gbm_model.predict_proba(train)\n",
    "#     test_pred = gbm_model.predict_proba(test)\n",
    "    \n",
    "#     return train_pred, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_rf(x_train, label_train):\n",
    "    \n",
    "    #train final model\n",
    "    rf_model = RandomForestClassifier(n_estimators=300,max_depth=6, max_features=10)\n",
    "    rf_model.fit(x_train, label_train)\n",
    "    \n",
    "    return rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_rf(func_train, func_label, func_test, k_fold_flag = 1):\n",
    "    \n",
    "    #Validation\n",
    "    \n",
    "    if k_fold_flag == 1:\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        skf.get_n_splits(func_train, func_label)\n",
    "\n",
    "        train_pred = pd.DataFrame()\n",
    "        for train_index, test_index in skf.split(func_train, func_label):\n",
    "\n",
    "            print test_index\n",
    "\n",
    "            kfold_train = func_train.iloc[train_index]\n",
    "            kfold_label = func_label.iloc[train_index]\n",
    "            kfold_test = func_train.iloc[test_index]\n",
    "\n",
    "            rf_model = run_rf(kfold_train, kfold_label)\n",
    "            kfold_pred = rf_model.predict_proba(kfold_test)\n",
    "            kfold_pred = pd.DataFrame(kfold_pred)\n",
    "            kfold_pred.columns = [\"rf_zero\", \"rf_one\", \"rf_two\", \"rf_three\"]\n",
    "\n",
    "            train_pred = pd.concat([train_pred, kfold_pred], axis = 0)\n",
    "\n",
    "        rf_model = run_rf(func_train, func_label)\n",
    "        test_pred = rf_model.predict_proba(func_test)\n",
    "        return train_pred, test_pred\n",
    "    \n",
    "    else:\n",
    "        rf_model = run_rf(func_train, func_label)\n",
    "        test_pred = rf_model.predict_proba(func_test)\n",
    "        return test_pred\n",
    "\n",
    "    #Testing\n",
    "#     rf_model = run_rf(train, label)\n",
    "    \n",
    "#     train_pred = rf_model.predict_proba(train)\n",
    "#     test_pred = rf_model.predict_proba(test)\n",
    "    \n",
    "#     return train_pred, test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(model, k_fold_flag = 1):\n",
    "    \n",
    "    if k_fold_flag == 1:\n",
    "        if model == \"xgb\":\n",
    "            model_train_res, model_test_res = init_xgb(train, label, test)\n",
    "        elif model == \"gbm\":\n",
    "            model_train_res, model_test_res = init_gbm(train, label, test)\n",
    "        elif model == \"rf\":\n",
    "            model_train_res, model_test_res = init_rf(train, label, test)\n",
    "\n",
    "        model_test_res = pd.DataFrame(model_test_res)\n",
    "        model_test_res.columns = [ model + \"_zero\", model + \"_one\", model + \"_two\", model + \"_three\"]\n",
    "\n",
    "        return model_train_res, model_test_res\n",
    "\n",
    "    else:\n",
    "        if model == \"xgb\":\n",
    "            model_test_res = init_xgb(train, label, test, 0)\n",
    "        elif model == \"gbm\":\n",
    "            model_test_res = init_gbm(train, label, test, 0)\n",
    "        elif model == \"rf\":\n",
    "            model_test_res = init_rf(train, label, test, 0)\n",
    "\n",
    "        model_test_res = pd.DataFrame(model_test_res)\n",
    "        model_test_res.columns = [ model + \"_zero\", model + \"_one\", model + \"_two\", model + \"_three\"]\n",
    "\n",
    "        return model_test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_level_stack(x_train, x_test):\n",
    "    \n",
    "    xgb_train_res, xgb_test_res = run_model(\"xgb\")    \n",
    "    gbm_train_res, gbm_test_res = run_model(\"gbm\")\n",
    "    rf_train_res, rf_test_res = run_model(\"rf\")\n",
    "\n",
    "    xgb_train_res.index = x_train.index\n",
    "    xgb_test_res.index = x_test.index\n",
    "    x_train = pd.concat([x_train, xgb_train_res], axis = 1)\n",
    "    x_test = pd.concat([x_test, xgb_test_res], axis = 1)\n",
    "\n",
    "    gbm_train_res.index = x_train.index\n",
    "    gbm_test_res.index = x_test.index\n",
    "    x_train = pd.concat([x_train, gbm_train_res], axis = 1)\n",
    "    x_test = pd.concat([x_test, gbm_test_res], axis = 1)\n",
    "\n",
    "    rf_train_res.index = x_train.index\n",
    "    rf_test_res.index = x_test.index    \n",
    "    x_train = pd.concat([x_train, rf_train_res], axis = 1)\n",
    "    x_test = pd.concat([x_test, rf_test_res], axis = 1)\n",
    "\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ..., 14892 14907 14985]\n",
      "[0]\ttrain-mlogloss:1.35098\n",
      "Will train until train-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.478553\n",
      "[100]\ttrain-mlogloss:0.231977\n",
      "[150]\ttrain-mlogloss:0.146942\n",
      "[200]\ttrain-mlogloss:0.115601\n",
      "[250]\ttrain-mlogloss:0.103066\n",
      "[300]\ttrain-mlogloss:0.097444\n",
      "[350]\ttrain-mlogloss:0.09419\n",
      "[400]\ttrain-mlogloss:0.092004\n",
      "[450]\ttrain-mlogloss:0.090131\n",
      "[499]\ttrain-mlogloss:0.088299\n",
      "[ 7203  7205  7207 ..., 19175 19180 19191]\n",
      "[0]\ttrain-mlogloss:1.34959\n",
      "Will train until train-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.47782\n",
      "[100]\ttrain-mlogloss:0.230246\n",
      "[150]\ttrain-mlogloss:0.144972\n",
      "[200]\ttrain-mlogloss:0.113453\n",
      "[250]\ttrain-mlogloss:0.100994\n",
      "[300]\ttrain-mlogloss:0.095341\n",
      "[350]\ttrain-mlogloss:0.092255\n",
      "[400]\ttrain-mlogloss:0.090138\n",
      "[450]\ttrain-mlogloss:0.088381\n",
      "[499]\ttrain-mlogloss:0.086651\n",
      "[14519 14521 14524 ..., 23409 23410 23411]\n",
      "[0]\ttrain-mlogloss:1.34937\n",
      "Will train until train-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.471076\n",
      "[100]\ttrain-mlogloss:0.222704\n",
      "[150]\ttrain-mlogloss:0.137275\n",
      "[200]\ttrain-mlogloss:0.10591\n",
      "[250]\ttrain-mlogloss:0.093593\n",
      "[300]\ttrain-mlogloss:0.087999\n",
      "[350]\ttrain-mlogloss:0.084945\n",
      "[400]\ttrain-mlogloss:0.082885\n",
      "[450]\ttrain-mlogloss:0.080955\n",
      "[499]\ttrain-mlogloss:0.079306\n",
      "[21886 21888 21905 ..., 31035 31039 31042]\n",
      "[0]\ttrain-mlogloss:1.34962\n",
      "Will train until train-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.476291\n",
      "[100]\ttrain-mlogloss:0.229043\n",
      "[150]\ttrain-mlogloss:0.144027\n",
      "[200]\ttrain-mlogloss:0.112604\n",
      "[250]\ttrain-mlogloss:0.09999\n",
      "[300]\ttrain-mlogloss:0.094269\n",
      "[350]\ttrain-mlogloss:0.091154\n",
      "[400]\ttrain-mlogloss:0.088922\n",
      "[450]\ttrain-mlogloss:0.087068\n",
      "[499]\ttrain-mlogloss:0.085252\n",
      "[24601 24602 24607 ..., 38482 38483 38484]\n",
      "[0]\ttrain-mlogloss:1.34961\n",
      "Will train until train-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.47598\n",
      "[100]\ttrain-mlogloss:0.228222\n",
      "[150]\ttrain-mlogloss:0.142814\n",
      "[200]\ttrain-mlogloss:0.111306\n",
      "[250]\ttrain-mlogloss:0.098797\n",
      "[300]\ttrain-mlogloss:0.093095\n",
      "[350]\ttrain-mlogloss:0.089994\n",
      "[400]\ttrain-mlogloss:0.087733\n",
      "[450]\ttrain-mlogloss:0.085905\n",
      "[499]\ttrain-mlogloss:0.084126\n",
      "[0]\ttrain-mlogloss:1.34959\n",
      "Will train until train-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.477094\n",
      "[100]\ttrain-mlogloss:0.229534\n",
      "[150]\ttrain-mlogloss:0.144384\n",
      "[200]\ttrain-mlogloss:0.113313\n",
      "[250]\ttrain-mlogloss:0.101033\n",
      "[300]\ttrain-mlogloss:0.095643\n",
      "[350]\ttrain-mlogloss:0.092749\n",
      "[400]\ttrain-mlogloss:0.090838\n",
      "[450]\ttrain-mlogloss:0.089208\n",
      "[499]\ttrain-mlogloss:0.087667\n",
      "[    0     1     2 ..., 14892 14907 14985]\n"
     ]
    }
   ],
   "source": [
    "# x_train, x_valid = first_level_stack(x_train, x_valid)\n",
    "train, test = first_level_stack(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def second_level_stack():\n",
    "    \n",
    "    xgb_test_res = run_model(\"xgb\", 0)\n",
    "    gbm_test_res = run_model(\"gbm\", 0)\n",
    "    rf_test_res = run_model(\"rf\", 0)\n",
    "    \n",
    "#     #Validation\n",
    "    pred_final = pd.DataFrame()\n",
    "    pred_final[\"pred_zero\"] = (xgb_test_res[\"xgb_zero\"] + gbm_test_res[\"gbm_zero\"] + rf_test_res[\"rf_zero\"])/3\n",
    "    pred_final[\"pred_one\"] = (xgb_test_res[\"xgb_one\"] + gbm_test_res[\"gbm_one\"] + rf_test_res[\"rf_one\"])/3\n",
    "    pred_final[\"pred_two\"] = (xgb_test_res[\"xgb_two\"] + gbm_test_res[\"gbm_two\"] + rf_test_res[\"rf_two\"])/3\n",
    "    pred_final[\"pred_three\"] = (xgb_test_res[\"xgb_three\"] + gbm_test_res[\"gbm_three\"] + rf_test_res[\"rf_three\"])/3\n",
    "\n",
    "    #Validation\n",
    "#     est = LogisticRegression(fit_intercept=False)\n",
    "#     est.fit(x_train, label_train)\n",
    "#     pred_final = est.predict_proba(x_valid)\n",
    "\n",
    "    #Testing\n",
    "#     est = LogisticRegression(fit_intercept=False)\n",
    "#     est.fit(train, label)\n",
    "#     pred_final = est.predict_proba(test)\n",
    "\n",
    "    return pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.34958\tvalidation-mlogloss:1.34947\n",
      "Multiple eval metrics have been passed: 'validation-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.475238\tvalidation-mlogloss:0.474808\n",
      "[100]\ttrain-mlogloss:0.228194\tvalidation-mlogloss:0.229196\n",
      "[150]\ttrain-mlogloss:0.142697\tvalidation-mlogloss:0.146065\n",
      "[200]\ttrain-mlogloss:0.111114\tvalidation-mlogloss:0.11749\n",
      "[250]\ttrain-mlogloss:0.097972\tvalidation-mlogloss:0.107859\n",
      "[300]\ttrain-mlogloss:0.091509\tvalidation-mlogloss:0.104543\n",
      "[350]\ttrain-mlogloss:0.087632\tvalidation-mlogloss:0.10341\n",
      "[400]\ttrain-mlogloss:0.084872\tvalidation-mlogloss:0.103029\n",
      "[450]\ttrain-mlogloss:0.082236\tvalidation-mlogloss:0.102887\n"
     ]
    }
   ],
   "source": [
    "pred_final = second_level_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_level_average():\n",
    "    \n",
    "    pred_final = pd.DataFrame()\n",
    "    pred_final[\"pred_zero\"] = (test[\"xgb_zero\"] + test[\"gbm_zero\"] + test[\"rf_zero\"])/3\n",
    "    pred_final[\"pred_one\"] = (test[\"xgb_one\"] + test[\"gbm_one\"] + test[\"rf_one\"])/3\n",
    "    pred_final[\"pred_two\"] = (test[\"xgb_two\"] + test[\"gbm_two\"] + test[\"rf_two\"])/3\n",
    "    pred_final[\"pred_three\"] = (test[\"xgb_three\"] + test[\"gbm_three\"] + test[\"rf_three\"])/3\n",
    "    \n",
    "    return pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_final = first_level_average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Submit\n",
    "\n",
    "pred_final.columns = ['Front','Left','Rear','Right']\n",
    "pred_final['Id'] = test_ids\n",
    "                      \n",
    "pred_final = pred_final[['Id','Front','Left','Rear','Right']]\n",
    "pred_final.to_csv(\"./subs/ens_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.8951027522\n"
     ]
    }
   ],
   "source": [
    "print 100 - metrics.log_loss(label_valid, pred_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
