{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./new/train.csv\")\n",
    "test = pd.read_csv(\"./new/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clean label columns\n",
    "label = train.pop(\"Target\")\n",
    "test_ids = test.pop(\"Id\")\n",
    "\n",
    "#drop columns\n",
    "train.drop(['Id', 'DetectedCamera'], inplace=True, axis=1)\n",
    "test.drop(['DetectedCamera'], inplace=True,axis=1)\n",
    "\n",
    "#Validation split\n",
    "x_train, x_valid, label_train, label_valid = train_test_split(train, label, test_size=0.2, random_state=4242, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_xgb(x_train, label_train, x_valid = None, label_valid = None):\n",
    "\n",
    "    # Set our parameters for xgboost\n",
    "    params = {}\n",
    "    params['objective'] = 'multi:softprob'\n",
    "    params['eval_metric'] = 'mlogloss'\n",
    "    params['eta'] = 0.02\n",
    "    params['num_class'] = 4\n",
    "    params['max_depth'] = 4\n",
    "    params['silent'] = 1\n",
    "    params['min_child_weight'] = 0\n",
    "    params['subsample'] = 0.8\n",
    "    params['colsample_bytree'] = 0.8\n",
    "    params['nthread'] = 13\n",
    "\n",
    "    d_train = xgb.DMatrix(x_train, label=label_train)\n",
    "    \n",
    "    if x_valid is not None:\n",
    "        d_valid = xgb.DMatrix(x_valid, label=label_valid)\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'validation')]\n",
    "    else:\n",
    "        watchlist = [(d_train, 'train')]\n",
    "        \n",
    "    bst = xgb.train(params, d_train, 500, watchlist, early_stopping_rounds=50, verbose_eval=50)\n",
    "    \n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_xgb(k_fold_flag = 1):\n",
    "\n",
    "#     Validate\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    skf.get_n_splits(x_train, label_train)\n",
    "    \n",
    "    train_pred = pd.DataFrame()\n",
    "    \n",
    "    if k_fold_flag == 1:\n",
    "        for train_index, test_index in skf.split(x_train, label_train):\n",
    "\n",
    "            print test_index\n",
    "\n",
    "            kfold_train = x_train.iloc[train_index]\n",
    "            kfold_label = label_train.iloc[train_index]\n",
    "            kfold_test = x_train.iloc[test_index]\n",
    "\n",
    "            xgb_model = run_xgb(kfold_train, kfold_label)\n",
    "            kfold_pred = xgb_model.predict(xgb.DMatrix(kfold_test))\n",
    "            kfold_pred = pd.DataFrame(kfold_pred)\n",
    "            kfold_pred.columns = [\"xgb_zero\", \"xgb_one\", \"xgb_two\", \"xgb_three\"]\n",
    "\n",
    "            train_pred = pd.concat([train_pred, kfold_pred], axis = 0)\n",
    "\n",
    "        bst = run_xgb(x_train, label_train, x_valid, label_valid)    \n",
    "        d_val = xgb.DMatrix(x_valid)\n",
    "        valid_pred = bst.predict(d_val)\n",
    "\n",
    "        return train_pred, valid_pred\n",
    "    else:\n",
    "        \n",
    "        bst = run_xgb(x_train, label_train, x_valid, label_valid)    \n",
    "        d_val = xgb.DMatrix(x_valid)\n",
    "        valid_pred = bst.predict(d_val)\n",
    "\n",
    "        return valid_pred\n",
    "        \n",
    "#     Test\n",
    "#     bst = run_xgb(train, label)\n",
    "    \n",
    "#     d_train = xgb.DMatrix(train)\n",
    "#     d_test = xgb.DMatrix(test)\n",
    "    \n",
    "#     train_pred = bst.predict(d_train)\n",
    "#     test_pred = bst.predict(d_test)\n",
    "\n",
    "#     return train_pred, test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_gbm(x_train, label_train, x_valid = None, label_valid = None):\n",
    "\n",
    "    gbm = GradientBoostingClassifier(n_estimators=500, max_depth=5, learning_rate=0.05, random_state=10)\n",
    "    gbm.fit(x_train, label_train)\n",
    "    \n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_gbm(k_fold_flag = 1):\n",
    "    \n",
    "#     #Validation\n",
    "    \n",
    "    if k_fold_flag == 1:\n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        skf.get_n_splits(x_train, label_train)\n",
    "\n",
    "        train_pred = pd.DataFrame()\n",
    "        for train_index, test_index in skf.split(x_train, label_train):\n",
    "\n",
    "            print test_index\n",
    "\n",
    "            kfold_train = x_train.iloc[train_index]\n",
    "            kfold_label = label_train.iloc[train_index]\n",
    "            kfold_test = x_train.iloc[test_index]\n",
    "\n",
    "            gbm_model = run_gbm(kfold_train, kfold_label)\n",
    "            kfold_pred = gbm_model.predict_proba(kfold_test)\n",
    "            kfold_pred = pd.DataFrame(kfold_pred)\n",
    "            kfold_pred.columns = [\"gbm_zero\", \"gbm_one\", \"gbm_two\", \"gbm_three\"]\n",
    "\n",
    "            train_pred = pd.concat([train_pred, kfold_pred], axis = 0)\n",
    "\n",
    "        gbm_model = run_gbm(x_train, label_train)\n",
    "        valid_pred = gbm_model.predict_proba(x_valid)\n",
    "\n",
    "        return train_pred, valid_pred\n",
    "    \n",
    "    else:\n",
    "        gbm_model = run_gbm(x_train, label_train)\n",
    "        valid_pred = gbm_model.predict_proba(x_valid)\n",
    "        return valid_pred\n",
    "        \n",
    "#     Testing\n",
    "#     gbm_model = run_gbm(train, label)\n",
    "    \n",
    "#     train_pred = gbm_model.predict_proba(train)\n",
    "#     test_pred = gbm_model.predict_proba(test)\n",
    "    \n",
    "#     return train_pred, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_rf(x_train, label_train):\n",
    "    \n",
    "    #train final model\n",
    "    rf_model = RandomForestClassifier(n_estimators=300,max_depth=6, max_features=10)\n",
    "    rf_model.fit(x_train, label_train)\n",
    "    \n",
    "    return rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rf(k_fold_flag = 1):\n",
    "    \n",
    "    #Validation\n",
    "    \n",
    "    if k_fold_flag == 1:\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        skf.get_n_splits(x_train, label_train)\n",
    "\n",
    "        train_pred = pd.DataFrame()\n",
    "        for train_index, test_index in skf.split(x_train, label_train):\n",
    "\n",
    "            print test_index\n",
    "\n",
    "            kfold_train = x_train.iloc[train_index]\n",
    "            kfold_label = label_train.iloc[train_index]\n",
    "            kfold_test = x_train.iloc[test_index]\n",
    "\n",
    "            rf_model = run_rf(kfold_train, kfold_label)\n",
    "            kfold_pred = rf_model.predict_proba(kfold_test)\n",
    "            kfold_pred = pd.DataFrame(kfold_pred)\n",
    "            kfold_pred.columns = [\"rf_zero\", \"rf_one\", \"rf_two\", \"rf_three\"]\n",
    "\n",
    "            train_pred = pd.concat([train_pred, kfold_pred], axis = 0)\n",
    "\n",
    "        rf_model = run_rf(x_train, label_train)\n",
    "        valid_pred = rf_model.predict_proba(x_valid)\n",
    "        return train_pred, valid_pred\n",
    "    \n",
    "    else:\n",
    "        rf_model = run_rf(x_train, label_train)\n",
    "        valid_pred = rf_model.predict_proba(x_valid)\n",
    "        return valid_pred\n",
    "\n",
    "    #Testing\n",
    "#     rf_model = run_rf(train, label)\n",
    "    \n",
    "#     train_pred = rf_model.predict_proba(train)\n",
    "#     test_pred = rf_model.predict_proba(test)\n",
    "    \n",
    "#     return train_pred, test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, k_fold_flag = 1):\n",
    "    \n",
    "    if k_fold_flag == 1:\n",
    "        if model == \"xgb\":\n",
    "            model_train_res, model_test_res = init_xgb()\n",
    "        elif model == \"gbm\":\n",
    "            model_train_res, model_test_res = init_gbm()\n",
    "        elif model == \"rf\":\n",
    "            model_train_res, model_test_res = init_rf()\n",
    "\n",
    "        model_test_res = pd.DataFrame(model_test_res)\n",
    "        model_test_res.columns = [ model + \"_zero\", model + \"_one\", model + \"_two\", model + \"_three\"]\n",
    "\n",
    "        return model_train_res, model_test_res\n",
    "\n",
    "    else:\n",
    "        if model == \"xgb\":\n",
    "            model_test_res = init_xgb(0)\n",
    "        elif model == \"gbm\":\n",
    "            model_test_res = init_gbm(0)\n",
    "        elif model == \"rf\":\n",
    "            model_test_res = init_rf(0)\n",
    "\n",
    "        model_test_res = pd.DataFrame(model_test_res)\n",
    "        model_test_res.columns = [ model + \"_zero\", model + \"_one\", model + \"_two\", model + \"_three\"]\n",
    "\n",
    "        return model_test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_level_stack(x_train, x_test):\n",
    "    \n",
    "    xgb_train_res, xgb_test_res = run_model(\"xgb\")    \n",
    "    gbm_train_res, gbm_test_res = run_model(\"gbm\")\n",
    "    rf_train_res, rf_test_res = run_model(\"rf\")\n",
    "\n",
    "    xgb_train_res.index = x_train.index\n",
    "    xgb_test_res.index = x_test.index\n",
    "    x_train = pd.concat([x_train, xgb_train_res], axis = 1)\n",
    "    x_test = pd.concat([x_test, xgb_test_res], axis = 1)\n",
    "\n",
    "    gbm_train_res.index = x_train.index\n",
    "    gbm_test_res.index = x_test.index\n",
    "    x_train = pd.concat([x_train, gbm_train_res], axis = 1)\n",
    "    x_test = pd.concat([x_test, gbm_test_res], axis = 1)\n",
    "\n",
    "    rf_train_res.index = x_train.index\n",
    "    rf_test_res.index = x_test.index    \n",
    "    x_train = pd.concat([x_train, rf_train_res], axis = 1)\n",
    "    x_test = pd.concat([x_test, rf_test_res], axis = 1)\n",
    "\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ..., 6800 6832 6843]\n",
      "[0]\ttrain-mlogloss:1.34962\n",
      "Will train until train-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.476543\n",
      "[100]\ttrain-mlogloss:0.229076\n",
      "[150]\ttrain-mlogloss:0.143314\n",
      "[200]\ttrain-mlogloss:0.111666\n",
      "[250]\ttrain-mlogloss:0.098729\n",
      "[300]\ttrain-mlogloss:0.09263\n",
      "[350]\ttrain-mlogloss:0.089178\n",
      "[400]\ttrain-mlogloss:0.086913\n",
      "[450]\ttrain-mlogloss:0.084751\n",
      "[ 5560  5601  5688 ..., 13317 13348 13396]\n",
      "[0]\ttrain-mlogloss:1.3496\n",
      "Will train until train-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.476427\n",
      "[100]\ttrain-mlogloss:0.228997\n",
      "[150]\ttrain-mlogloss:0.143141\n",
      "[200]\ttrain-mlogloss:0.111176\n",
      "[250]\ttrain-mlogloss:0.098233\n",
      "[300]\ttrain-mlogloss:0.092085\n",
      "[350]\ttrain-mlogloss:0.088679\n",
      "[400]\ttrain-mlogloss:0.086276\n",
      "[450]\ttrain-mlogloss:0.084157\n",
      "[12167 12174 12176 ..., 19565 19585 19609]\n",
      "[0]\ttrain-mlogloss:1.34954\n",
      "Will train until train-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.475796\n",
      "[100]\ttrain-mlogloss:0.228278\n",
      "[150]\ttrain-mlogloss:0.142964\n",
      "[200]\ttrain-mlogloss:0.111409\n",
      "[250]\ttrain-mlogloss:0.098701\n",
      "[300]\ttrain-mlogloss:0.093024\n",
      "[350]\ttrain-mlogloss:0.089895\n",
      "[400]\ttrain-mlogloss:0.087581\n",
      "[450]\ttrain-mlogloss:0.085483\n",
      "[18082 18089 18135 ..., 26104 26166 26217]\n",
      "[0]\ttrain-mlogloss:1.34958\n",
      "Will train until train-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.476086\n",
      "[100]\ttrain-mlogloss:0.228695\n",
      "[150]\ttrain-mlogloss:0.143354\n",
      "[200]\ttrain-mlogloss:0.111705\n",
      "[250]\ttrain-mlogloss:0.098926\n",
      "[300]\ttrain-mlogloss:0.093106\n",
      "[350]\ttrain-mlogloss:0.089911\n",
      "[400]\ttrain-mlogloss:0.087642\n",
      "[450]\ttrain-mlogloss:0.085472\n",
      "[24558 24559 24560 ..., 30785 30786 30787]\n",
      "[0]\ttrain-mlogloss:1.34955\n",
      "Will train until train-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.474971\n",
      "[100]\ttrain-mlogloss:0.226935\n",
      "[150]\ttrain-mlogloss:0.1412\n",
      "[200]\ttrain-mlogloss:0.109382\n",
      "[250]\ttrain-mlogloss:0.096592\n",
      "[300]\ttrain-mlogloss:0.090777\n",
      "[350]\ttrain-mlogloss:0.087446\n",
      "[400]\ttrain-mlogloss:0.085086\n",
      "[450]\ttrain-mlogloss:0.082964\n",
      "[0]\ttrain-mlogloss:1.34957\tvalidation-mlogloss:1.34955\n",
      "Multiple eval metrics have been passed: 'validation-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.477504\tvalidation-mlogloss:0.478027\n",
      "[100]\ttrain-mlogloss:0.229744\tvalidation-mlogloss:0.231475\n",
      "[150]\ttrain-mlogloss:0.144189\tvalidation-mlogloss:0.147829\n",
      "[200]\ttrain-mlogloss:0.112468\tvalidation-mlogloss:0.118512\n",
      "[250]\ttrain-mlogloss:0.09985\tvalidation-mlogloss:0.108274\n",
      "[300]\ttrain-mlogloss:0.094068\tvalidation-mlogloss:0.104621\n",
      "[350]\ttrain-mlogloss:0.090906\tvalidation-mlogloss:0.103252\n",
      "[400]\ttrain-mlogloss:0.088709\tvalidation-mlogloss:0.102583\n",
      "[450]\ttrain-mlogloss:0.086852\tvalidation-mlogloss:0.102273\n",
      "[   0    1    2 ..., 6800 6832 6843]\n",
      "[ 5560  5601  5688 ..., 13317 13348 13396]\n",
      "[12167 12174 12176 ..., 19565 19585 19609]\n",
      "[18082 18089 18135 ..., 26104 26166 26217]\n",
      "[24558 24559 24560 ..., 30785 30786 30787]\n",
      "[   0    1    2 ..., 6800 6832 6843]\n",
      "[ 5560  5601  5688 ..., 13317 13348 13396]\n",
      "[12167 12174 12176 ..., 19565 19585 19609]\n",
      "[18082 18089 18135 ..., 26104 26166 26217]\n",
      "[24558 24559 24560 ..., 30785 30786 30787]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid = first_level_stack(x_train, x_valid)\n",
    "# train, test = first_level_stack(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def second_level_stack():\n",
    "    \n",
    "    xgb_test_res = run_model(\"xgb\", 0)\n",
    "    gbm_test_res = run_model(\"gbm\", 0)\n",
    "    rf_test_res = run_model(\"rf\", 0)\n",
    "    \n",
    "#     #Validation\n",
    "    pred_final = pd.DataFrame()\n",
    "    pred_final[\"pred_zero\"] = (xgb_test_res[\"xgb_zero\"] + gbm_test_res[\"gbm_zero\"] + rf_test_res[\"rf_zero\"])/3\n",
    "    pred_final[\"pred_one\"] = (xgb_test_res[\"xgb_one\"] + gbm_test_res[\"gbm_one\"] + rf_test_res[\"rf_one\"])/3\n",
    "    pred_final[\"pred_two\"] = (xgb_test_res[\"xgb_two\"] + gbm_test_res[\"gbm_two\"] + rf_test_res[\"rf_two\"])/3\n",
    "    pred_final[\"pred_three\"] = (xgb_test_res[\"xgb_three\"] + gbm_test_res[\"gbm_three\"] + rf_test_res[\"rf_three\"])/3\n",
    "\n",
    "    #Validation\n",
    "#     est = LogisticRegression(fit_intercept=False)\n",
    "#     est.fit(x_train, label_train)\n",
    "#     pred_final = est.predict_proba(x_valid)\n",
    "\n",
    "    #Testing\n",
    "#     est = LogisticRegression(fit_intercept=False)\n",
    "#     est.fit(train, label)\n",
    "#     pred_final = est.predict_proba(test)\n",
    "\n",
    "    return pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.34958\tvalidation-mlogloss:1.34947\n",
      "Multiple eval metrics have been passed: 'validation-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation-mlogloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.475238\tvalidation-mlogloss:0.474808\n",
      "[100]\ttrain-mlogloss:0.228194\tvalidation-mlogloss:0.229196\n",
      "[150]\ttrain-mlogloss:0.142697\tvalidation-mlogloss:0.146065\n",
      "[200]\ttrain-mlogloss:0.111114\tvalidation-mlogloss:0.11749\n",
      "[250]\ttrain-mlogloss:0.097972\tvalidation-mlogloss:0.107859\n",
      "[300]\ttrain-mlogloss:0.091509\tvalidation-mlogloss:0.104543\n",
      "[350]\ttrain-mlogloss:0.087632\tvalidation-mlogloss:0.10341\n",
      "[400]\ttrain-mlogloss:0.084872\tvalidation-mlogloss:0.103029\n",
      "[450]\ttrain-mlogloss:0.082236\tvalidation-mlogloss:0.102887\n"
     ]
    }
   ],
   "source": [
    "pred_final = second_level_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_level_average():\n",
    "    \n",
    "    pred_final = pd.DataFrame()\n",
    "    pred_final[\"pred_zero\"] = (test[\"xgb_zero\"] + test[\"gbm_zero\"] + test[\"rf_zero\"])/3\n",
    "    pred_final[\"pred_one\"] = (test[\"xgb_one\"] + test[\"gbm_one\"] + test[\"rf_one\"])/3\n",
    "    pred_final[\"pred_two\"] = (test[\"xgb_two\"] + test[\"gbm_two\"] + test[\"rf_two\"])/3\n",
    "    pred_final[\"pred_three\"] = (test[\"xgb_three\"] + test[\"gbm_three\"] + test[\"rf_three\"])/3\n",
    "    \n",
    "    return pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_final = first_level_average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Submit\n",
    "\n",
    "pred_final.columns = ['Front','Left','Rear','Right']\n",
    "pred_final['Id'] = test_ids\n",
    "                      \n",
    "pred_final = pred_final[['Id','Front','Left','Rear','Right']]\n",
    "pred_final.to_csv(\"./subs/ens_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.8951027522\n"
     ]
    }
   ],
   "source": [
    "print 100 - metrics.log_loss(label_valid, pred_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
