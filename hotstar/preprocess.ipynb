{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm_pandas(tqdm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_json('train_data.json',orient=\"index\")\n",
    "test_data = pd.read_json('test_data.json',orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set index\n",
    "train_data.reset_index(level = 0, inplace = True)\n",
    "train_data.rename(columns={'index':'ID'}, inplace=True)\n",
    "\n",
    "test_data.reset_index(level = 0, inplace = True)\n",
    "test_data.rename(columns={'index':'ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data has 200000 rows and 7 columns\n",
      "test_data data has 100000 rows and 6 columns\n"
     ]
    }
   ],
   "source": [
    "#check data\n",
    "print ('Train data has {} rows and {} columns'.format(train_data.shape[0],train_data.shape[1]))\n",
    "print ('test_data data has {} rows and {} columns'.format(test_data.shape[0],test_data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encode Target Variable\n",
    "train_data = train_data.replace({'segment':{'pos':1,'neg':0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.923725\n",
       "1    0.076275\n",
       "Name: segment, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check target variable count\n",
    "train_data['segment'].value_counts()/train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating separate columns for genres, dow and tod variables\n",
    "\n",
    "genre_data = [[str(\"genre_\" + i) for i in re.sub(pattern='\\:\\d+',repl='',string=x).split(\",\")] for x in train_data['genres']]\n",
    "dow_data = [[str(\"dow_\" + i) for i in re.sub(pattern='\\:\\d+', repl='', string = x).split(',')] for x in train_data['dow']]\n",
    "tod_data = [[str(\"tod_\" + i) for i in re.sub(pattern='\\:\\d+', repl='', string = x).split(',')] for x in train_data['tod']]\n",
    "cities_data = [[str(\"cities_\" + i) for i in re.sub(pattern='\\:\\d+', repl='', string = x).split(',')] for x in train_data['cities']]\n",
    "\n",
    "genre_data = frozenset.union(*pd.Series(genre_data).apply(frozenset))\n",
    "dow_data = frozenset.union(*pd.Series(dow_data).apply(frozenset))\n",
    "tod_data = frozenset.union(*pd.Series(tod_data).apply(frozenset))\n",
    "cities_data = frozenset.union(*pd.Series(cities_data).apply(frozenset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_freq(row):\n",
    "        \n",
    "    genre_dict = {}\n",
    "    for genre in row.genres.split(\",\"):\n",
    "        genre_name, genre_wt = genre.split(\":\")\n",
    "        genre_dict[str(\"genre_\" + genre_name)] = int(genre_wt)\n",
    "    \n",
    "    genre_freq = {}\n",
    "    for i in genre_data:\n",
    "        if i in genre_dict:\n",
    "            genre_freq[i] = genre_dict[i] \n",
    "        else:\n",
    "            genre_freq[i] = 0            \n",
    "\n",
    "    return pd.Series(genre_freq)\n",
    "\n",
    "def get_dow_freq(row):\n",
    "    \n",
    "    dow_dict = {}\n",
    "    for dow in row.dow.split(\",\"):\n",
    "        dow_name, dow_wt = dow.split(\":\")\n",
    "        dow_dict[int(dow_name)] = int(dow_wt)\n",
    "    \n",
    "    dow_freq = {}\n",
    "    for i in dow_data:\n",
    "        if i in dow_dict:\n",
    "            dow_freq[i] = dow_dict[i] \n",
    "        else:\n",
    "            dow_freq[i] = 0            \n",
    "\n",
    "    return pd.Series(dow_freq)\n",
    "\n",
    "def get_tod_freq(row):\n",
    "    \n",
    "    tod_dict = {}\n",
    "    for tod in row.tod.split(\",\"):\n",
    "        tod_name, tod_wt = tod.split(\":\")\n",
    "        tod_dict[int(tod_name)] = int(tod_wt)\n",
    "    \n",
    "    tod_freq = {}\n",
    "    for i in tod_data:\n",
    "        if i in tod_dict:\n",
    "            tod_freq[i] = tod_dict[i] \n",
    "        else:\n",
    "            tod_freq[i] = 0            \n",
    "\n",
    "    return pd.Series(tod_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_feats = train_data.progress_apply(get_genre_freq, axis = 1)\n",
    "dow_feats = train_data.progress_apply(get_dow_freq, axis = 1)\n",
    "tod_feats = train_data.progress_apply(get_tod_freq, axis = 1)\n",
    "\n",
    "train_data = pd.concat([train_data, genre_feats], axis = 1)\n",
    "train_data = pd.concat([train_data, dow_feats], axis = 1)\n",
    "train_data = pd.concat([train_data, tod_feats], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100001it [01:00, 1663.43it/s]        \n",
      "100001it [00:51, 1955.04it/s]        \n",
      "100001it [00:53, 1867.17it/s]        \n"
     ]
    }
   ],
   "source": [
    "genre_feats = test_data.progress_apply(get_genre_freq, axis = 1)\n",
    "dow_feats = test_data.progress_apply(get_dow_freq, axis = 1)\n",
    "tod_feats = test_data.progress_apply(get_tod_freq, axis = 1)\n",
    "\n",
    "test_data = pd.concat([test_data, genre_feats], axis = 1)\n",
    "test_data = pd.concat([test_data, dow_feats], axis = 1)\n",
    "test_data = pd.concat([test_data, tod_feats], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/73 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏         | 1/73 [00:00<00:42,  1.68it/s]\u001b[A\n",
      "1721it [00:00,  2.39it/s]                     \u001b[A\n",
      "3645it [00:00,  3.42it/s]\u001b[A\n",
      "5433it [00:00,  4.88it/s]\u001b[A\n",
      "7263it [00:00,  6.98it/s]\u001b[A\n",
      "8887it [00:01,  9.96it/s]\u001b[A\n",
      "10778it [00:01, 14.23it/s]\u001b[A\n",
      "12832it [00:01, 20.32it/s]\u001b[A\n",
      "14559it [00:01, 29.01it/s]\u001b[A\n",
      "16474it [00:01, 41.42it/s]\u001b[A\n",
      "18234it [00:01, 59.11it/s]\u001b[A\n",
      "20169it [00:01, 84.33it/s]\u001b[A\n",
      "21966it [00:01, 120.23it/s]\u001b[A\n",
      "23836it [00:01, 171.28it/s]\u001b[A\n",
      "25641it [00:02, 243.63it/s]\u001b[A\n",
      "27413it [00:02, 345.88it/s]\u001b[A\n",
      "29153it [00:02, 489.92it/s]\u001b[A\n",
      "30919it [00:02, 691.66it/s]\u001b[A\n",
      "32796it [00:02, 972.72it/s]\u001b[A\n",
      "35032it [00:02, 1364.16it/s]\u001b[A\n",
      "36953it [00:02, 1889.62it/s]\u001b[A\n",
      "38858it [00:02, 2578.07it/s]\u001b[A\n",
      "40707it [00:02, 3433.03it/s]\u001b[A\n",
      "42457it [00:02, 4521.32it/s]\u001b[A\n",
      "44203it [00:03, 5772.81it/s]\u001b[A\n",
      "45915it [00:03, 6975.98it/s]\u001b[A\n",
      "47521it [00:03, 8351.78it/s]\u001b[A\n",
      "49319it [00:03, 9949.37it/s]\u001b[A\n",
      "51097it [00:03, 11462.89it/s]\u001b[A\n",
      "52852it [00:03, 12792.65it/s]\u001b[A\n",
      "54746it [00:03, 14171.35it/s]\u001b[A\n",
      "56510it [00:03, 14490.78it/s]\u001b[A\n",
      "58316it [00:03, 15397.23it/s]\u001b[A\n",
      "60043it [00:04, 15678.66it/s]\u001b[A\n",
      "61743it [00:04, 15999.90it/s]\u001b[A\n",
      "63437it [00:04, 15973.18it/s]\u001b[A\n",
      "65217it [00:04, 16476.58it/s]\u001b[A\n",
      "66915it [00:04, 16355.80it/s]\u001b[A\n",
      "68586it [00:04, 16252.37it/s]\u001b[A\n",
      "70237it [00:04, 16038.15it/s]\u001b[A\n",
      "71859it [00:04, 13894.64it/s]\u001b[A\n",
      "73313it [00:04, 12529.13it/s]\u001b[A\n",
      "74718it [00:05, 12946.97it/s]\u001b[A\n",
      "76633it [00:05, 14339.74it/s]\u001b[A\n",
      "78497it [00:05, 15404.85it/s]\u001b[A\n",
      "80119it [00:05, 15494.94it/s]\u001b[A\n",
      "81726it [00:05, 13848.89it/s]\u001b[A\n",
      "83184it [00:05, 13339.10it/s]\u001b[A\n",
      "84573it [00:05, 13198.10it/s]\u001b[A\n",
      "85932it [00:05, 12181.68it/s]\u001b[A\n",
      "87193it [00:05, 12207.47it/s]\u001b[A\n",
      "88766it [00:06, 13081.40it/s]\u001b[A\n",
      "90298it [00:06, 13680.34it/s]\u001b[A\n",
      "91702it [00:06, 13783.29it/s]\u001b[A\n",
      "93401it [00:06, 14608.58it/s]\u001b[A\n",
      "95234it [00:06, 15555.38it/s]\u001b[A\n",
      "97030it [00:06, 16204.49it/s]\u001b[A\n",
      "98709it [00:06, 16375.00it/s]\u001b[A\n",
      "100371it [00:06, 16367.61it/s]\u001b[A\n",
      "102025it [00:06, 16388.26it/s]\u001b[A\n",
      "103676it [00:06, 15554.38it/s]\u001b[A\n",
      "105249it [00:07, 15341.48it/s]\u001b[A\n",
      "106796it [00:07, 14193.18it/s]\u001b[A\n",
      "108242it [00:07, 13631.73it/s]\u001b[A\n",
      "109629it [00:07, 12521.60it/s]\u001b[A\n",
      "110915it [00:07, 12416.09it/s]\u001b[A\n",
      "112749it [00:07, 13748.17it/s]\u001b[A\n",
      "114546it [00:07, 14789.79it/s]\u001b[A\n",
      "116323it [00:07, 15571.07it/s]\u001b[A\n",
      "117937it [00:07, 15544.47it/s]\u001b[A\n",
      "119532it [00:08, 14805.59it/s]\u001b[A\n",
      "121048it [00:08, 13870.06it/s]\u001b[A\n",
      "122704it [00:08, 14579.63it/s]\u001b[A\n",
      "124403it [00:08, 15226.22it/s]\u001b[A\n",
      "126124it [00:08, 15771.27it/s]\u001b[A\n",
      "127729it [00:08, 14606.34it/s]\u001b[A\n",
      "129723it [00:08, 15879.68it/s]\u001b[A\n",
      "131369it [00:08, 16010.70it/s]\u001b[A\n",
      "133011it [00:08, 14359.55it/s]\u001b[A\n",
      "134508it [00:09, 14209.49it/s]\u001b[A\n",
      "135996it [00:09, 14403.78it/s]\u001b[A\n",
      "137467it [00:09, 14317.90it/s]\u001b[A\n",
      "138921it [00:09, 14107.57it/s]\u001b[A\n",
      "140348it [00:09, 13840.24it/s]\u001b[A\n",
      "141745it [00:09, 13231.19it/s]\u001b[A\n",
      "143083it [00:09, 13089.10it/s]\u001b[A\n",
      "144403it [00:09, 12069.50it/s]\u001b[A\n",
      "145633it [00:09, 11420.25it/s]\u001b[A\n",
      "147182it [00:10, 12395.48it/s]\u001b[A\n",
      "148607it [00:10, 12896.96it/s]\u001b[A\n",
      "150141it [00:10, 13543.96it/s]\u001b[A\n",
      "152289it [00:10, 15230.66it/s]\u001b[A\n",
      "153904it [00:10, 14479.17it/s]\u001b[A\n",
      "155424it [00:10, 13599.77it/s]\u001b[A\n",
      "157068it [00:10, 14341.95it/s]\u001b[A\n",
      "158780it [00:10, 15075.30it/s]\u001b[A\n",
      "160336it [00:10, 14931.86it/s]\u001b[A\n",
      "161863it [00:11, 14354.39it/s]\u001b[A\n",
      "163327it [00:11, 13316.17it/s]\u001b[A\n",
      "164694it [00:11, 13130.79it/s]\u001b[A\n",
      "166033it [00:11, 13028.27it/s]\u001b[A\n",
      "167393it [00:11, 13186.69it/s]\u001b[A\n",
      "168903it [00:11, 13706.68it/s]\u001b[A\n",
      "170288it [00:11, 13163.32it/s]\u001b[A\n",
      "171664it [00:11, 13334.72it/s]\u001b[A\n",
      "173009it [00:11, 12767.52it/s]\u001b[A\n",
      "174299it [00:12, 12050.03it/s]\u001b[A\n",
      "175522it [00:12, 11212.72it/s]\u001b[A\n",
      "176667it [00:12, 10916.15it/s]\u001b[A\n",
      "177906it [00:12, 11318.85it/s]\u001b[A\n",
      "179150it [00:12, 11569.70it/s]\u001b[A\n",
      "180438it [00:12, 11933.18it/s]\u001b[A\n",
      "181836it [00:12, 12481.11it/s]\u001b[A\n",
      "183548it [00:12, 13583.65it/s]\u001b[A\n",
      "184946it [00:12, 13251.49it/s]\u001b[A\n",
      "186301it [00:13, 12974.20it/s]\u001b[A\n",
      "187621it [00:13, 12882.59it/s]\u001b[A\n",
      "188925it [00:13, 12678.18it/s]\u001b[A\n",
      "190206it [00:13, 12712.89it/s]\u001b[A\n",
      "191486it [00:13, 11872.26it/s]\u001b[A\n",
      "192691it [00:13, 11680.96it/s]\u001b[A\n",
      "193872it [00:13, 11688.41it/s]\u001b[A\n",
      "195098it [00:13, 11853.56it/s]\u001b[A\n",
      "196291it [00:13, 11581.45it/s]\u001b[A\n",
      "197570it [00:13, 11917.43it/s]\u001b[A\n",
      "199170it [00:14, 12903.16it/s]\u001b[A\n",
      "200000it [00:14, 13950.35it/s]\u001b[A\n",
      "  0%|          | 0/72 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏         | 1/72 [00:00<00:15,  4.50it/s]\u001b[A\n",
      "1927it [00:00,  6.42it/s]                     \u001b[A\n",
      "3645it [00:00,  9.17it/s]\u001b[A\n",
      "5321it [00:00, 13.10it/s]\u001b[A\n",
      "7227it [00:00, 18.71it/s]\u001b[A\n",
      "9097it [00:00, 26.72it/s]\u001b[A\n",
      "10801it [00:00, 38.14it/s]\u001b[A\n",
      "12441it [00:00, 54.43it/s]\u001b[A\n",
      "14407it [00:01, 77.67it/s]\u001b[A\n",
      "16211it [00:01, 110.76it/s]\u001b[A\n",
      "17980it [00:01, 157.80it/s]\u001b[A\n",
      "19812it [00:01, 224.58it/s]\u001b[A\n",
      "21907it [00:01, 319.36it/s]\u001b[A\n",
      "23823it [00:01, 453.00it/s]\u001b[A\n",
      "25701it [00:01, 639.78it/s]\u001b[A\n",
      "27793it [00:01, 902.15it/s]\u001b[A\n",
      "29696it [00:01, 1263.02it/s]\u001b[A\n",
      "31597it [00:01, 1749.73it/s]\u001b[A\n",
      "33448it [00:02, 2396.08it/s]\u001b[A\n",
      "35265it [00:02, 3236.34it/s]\u001b[A\n",
      "37071it [00:02, 4246.44it/s]\u001b[A\n",
      "38804it [00:02, 5470.77it/s]\u001b[A\n",
      "40597it [00:02, 6911.32it/s]\u001b[A\n",
      "42335it [00:02, 8402.91it/s]\u001b[A\n",
      "44060it [00:02, 9807.50it/s]\u001b[A\n",
      "45750it [00:02, 11178.20it/s]\u001b[A\n",
      "47549it [00:02, 12609.78it/s]\u001b[A\n",
      "49265it [00:02, 13308.94it/s]\u001b[A\n",
      "50955it [00:03, 14215.00it/s]\u001b[A\n",
      "52624it [00:03, 14798.32it/s]\u001b[A\n",
      "54359it [00:03, 15481.17it/s]\u001b[A\n",
      "56070it [00:03, 15935.63it/s]\u001b[A\n",
      "57761it [00:03, 15960.64it/s]\u001b[A\n",
      "59425it [00:03, 15757.49it/s]\u001b[A\n",
      "61049it [00:03, 15368.17it/s]\u001b[A\n",
      "62996it [00:03, 16404.06it/s]\u001b[A\n",
      "64681it [00:03, 16437.54it/s]\u001b[A\n",
      "66356it [00:04, 16269.41it/s]\u001b[A\n",
      "68006it [00:04, 16285.08it/s]\u001b[A\n",
      "69729it [00:04, 16556.87it/s]\u001b[A\n",
      "71663it [00:04, 17302.98it/s]\u001b[A\n",
      "73411it [00:04, 17155.08it/s]\u001b[A\n",
      "75139it [00:04, 16655.75it/s]\u001b[A\n",
      "76817it [00:04, 16420.22it/s]\u001b[A\n",
      "78625it [00:04, 16882.64it/s]\u001b[A\n",
      "80346it [00:04, 16978.28it/s]\u001b[A\n",
      "82051it [00:04, 16994.14it/s]\u001b[A\n",
      "83975it [00:05, 17609.73it/s]\u001b[A\n",
      "85745it [00:05, 16895.02it/s]\u001b[A\n",
      "87493it [00:05, 17062.42it/s]\u001b[A\n",
      "89284it [00:05, 17303.63it/s]\u001b[A\n",
      "91304it [00:05, 18081.22it/s]\u001b[A\n",
      "93127it [00:05, 16523.21it/s]\u001b[A\n",
      "95051it [00:05, 17252.96it/s]\u001b[A\n",
      "96810it [00:05, 16583.58it/s]\u001b[A\n",
      "98770it [00:05, 17384.27it/s]\u001b[A\n",
      "100000it [00:06, 16499.90it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "# sum of watch time from titles\n",
    "\n",
    "def get_sum_wt(row):\n",
    "    \n",
    "    sum_wt = 0\n",
    "    \n",
    "    for title in row.titles.split(\",\"):\n",
    "\n",
    "        try: #to ignore blanks\n",
    "\n",
    "            title_name, title_wt = title.split(\":\")\n",
    "            sum_wt += int(title_wt)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return sum_wt\n",
    "\n",
    "train_data[\"sum_wt\"] = train_data.progress_apply(get_sum_wt, axis = 1)\n",
    "test_data[\"sum_wt\"] = test_data.progress_apply(get_sum_wt, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Count variables\n",
    "def wcount(p):\n",
    "    return p.count(',')+1\n",
    "\n",
    "train_data['title_count'] = train_data['titles'].map(wcount)\n",
    "train_data['genres_count'] = train_data['genres'].map(wcount)\n",
    "train_data['cities_count'] = train_data['cities'].map(wcount)\n",
    "train_data['tod_count'] = train_data['tod'].map(wcount)\n",
    "train_data['dow_count'] = train_data['dow'].map(wcount)\n",
    "\n",
    "test_data['title_count'] = test_data['titles'].map(wcount)\n",
    "test_data['genres_count'] = test_data['genres'].map(wcount)\n",
    "test_data['cities_count'] = test_data['cities'].map(wcount)\n",
    "test_data['tod_count'] = test_data['tod'].map(wcount)\n",
    "test_data['dow_count'] = test_data['dow'].map(wcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Doubtful about how to utilize cities -- too many cities to one-hot encode\n",
    "train_data.drop(['cities','dow','genres','titles','tod'], inplace=True, axis=1)\n",
    "test_data.drop(['cities','dow','genres','titles','tod'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_data.csv\", index = False)\n",
    "test_data.to_csv(\"test_data.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
