{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm_pandas(tqdm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_json('train_data.json',orient=\"index\")\n",
    "test_data = pd.read_json('test_data.json',orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set index\n",
    "train_data.reset_index(level = 0, inplace = True)\n",
    "train_data.rename(columns={'index':'ID'}, inplace=True)\n",
    "\n",
    "test_data.reset_index(level = 0, inplace = True)\n",
    "test_data.rename(columns={'index':'ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data has 200000 rows and 7 columns\n",
      "test_data data has 100000 rows and 6 columns\n"
     ]
    }
   ],
   "source": [
    "#check data\n",
    "print ('Train data has {} rows and {} columns'.format(train_data.shape[0],train_data.shape[1]))\n",
    "print ('test_data data has {} rows and {} columns'.format(test_data.shape[0],test_data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encode Target Variable\n",
    "train_data = train_data.replace({'segment':{'pos':1,'neg':0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.923725\n",
       "1    0.076275\n",
       "Name: segment, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check target variable count\n",
    "train_data['segment'].value_counts()/train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating separate columns for genres, dow and tod variables\n",
    "\n",
    "genre_data = [[str(\"genre_\" + i) for i in re.sub(pattern='\\:\\d+',repl='',string=x).split(\",\")] for x in train_data['genres']]\n",
    "dow_data = [[str(\"dow_\" + i) for i in re.sub(pattern='\\:\\d+', repl='', string = x).split(',')] for x in train_data['dow']]\n",
    "tod_data = [[str(\"tod_\" + i) for i in re.sub(pattern='\\:\\d+', repl='', string = x).split(',')] for x in train_data['tod']]\n",
    "cities_data = [[str(\"cities_\" + i) for i in re.sub(pattern='\\:\\d+', repl='', string = x).split(',')] for x in train_data['cities']]\n",
    "\n",
    "genre_data = frozenset.union(*pd.Series(genre_data).apply(frozenset))\n",
    "dow_data = frozenset.union(*pd.Series(dow_data).apply(frozenset))\n",
    "tod_data = frozenset.union(*pd.Series(tod_data).apply(frozenset))\n",
    "cities_data = frozenset.union(*pd.Series(cities_data).apply(frozenset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_genre_freq(row):\n",
    "        \n",
    "    genre_dict = {}\n",
    "    for genre in row.genres.split(\",\"):\n",
    "        genre_name, genre_wt = genre.split(\":\")\n",
    "        genre_dict[str(\"genre_\" + genre_name)] = int(genre_wt)\n",
    "    \n",
    "    genre_freq = {}\n",
    "    for i in genre_data:\n",
    "        if i in genre_dict:\n",
    "            genre_freq[i] = genre_dict[i] \n",
    "        else:\n",
    "            genre_freq[i] = 0            \n",
    "\n",
    "    return pd.Series(genre_freq)\n",
    "\n",
    "def get_dow_freq(row):\n",
    "    \n",
    "    dow_dict = {}\n",
    "    for dow in row.dow.split(\",\"):\n",
    "        dow_name, dow_wt = dow.split(\":\")\n",
    "        dow_dict[str(\"dow_\" + dow_name)] = int(dow_wt)\n",
    "    \n",
    "    dow_freq = {}\n",
    "    for i in dow_data:\n",
    "        if i in dow_dict:\n",
    "            dow_freq[i] = dow_dict[i] \n",
    "        else:\n",
    "            dow_freq[i] = 0            \n",
    "\n",
    "    return pd.Series(dow_freq)\n",
    "\n",
    "def get_tod_freq(row):\n",
    "    \n",
    "    tod_dict = {}\n",
    "    for tod in row.tod.split(\",\"):\n",
    "        tod_name, tod_wt = tod.split(\":\")\n",
    "        tod_dict[str(\"tod_\" + tod_name)] = int(tod_wt)\n",
    "    \n",
    "    tod_freq = {}\n",
    "    for i in tod_data:\n",
    "        if i in tod_dict:\n",
    "            tod_freq[i] = tod_dict[i] \n",
    "        else:\n",
    "            tod_freq[i] = 0            \n",
    "\n",
    "    return pd.Series(tod_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200001it [01:38, 2038.93it/s]        \n",
      "200001it [01:33, 2130.31it/s]        \n",
      "200001it [01:37, 2043.44it/s]        \n"
     ]
    }
   ],
   "source": [
    "genre_feats = train_data.progress_apply(get_genre_freq, axis = 1)\n",
    "dow_feats = train_data.progress_apply(get_dow_freq, axis = 1)\n",
    "tod_feats = train_data.progress_apply(get_tod_freq, axis = 1)\n",
    "\n",
    "train_data = pd.concat([train_data, genre_feats], axis = 1)\n",
    "train_data = pd.concat([train_data, dow_feats], axis = 1)\n",
    "train_data = pd.concat([train_data, tod_feats], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100001it [00:47, 2117.54it/s]        \n",
      "100001it [00:43, 2305.85it/s]        \n",
      "100001it [00:46, 2171.10it/s]        \n"
     ]
    }
   ],
   "source": [
    "genre_feats = test_data.progress_apply(get_genre_freq, axis = 1)\n",
    "dow_feats = test_data.progress_apply(get_dow_freq, axis = 1)\n",
    "tod_feats = test_data.progress_apply(get_tod_freq, axis = 1)\n",
    "\n",
    "test_data = pd.concat([test_data, genre_feats], axis = 1)\n",
    "test_data = pd.concat([test_data, dow_feats], axis = 1)\n",
    "test_data = pd.concat([test_data, tod_feats], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200000it [00:09, 20038.74it/s]                \n",
      "100000it [00:04, 20353.57it/s]                \n"
     ]
    }
   ],
   "source": [
    "# sum of watch time from titles\n",
    "\n",
    "def get_sum_wt(row):\n",
    "    \n",
    "    sum_wt = 0\n",
    "    \n",
    "    for title in row.titles.split(\",\"):\n",
    "\n",
    "        try: #to ignore blanks\n",
    "\n",
    "            title_name, title_wt = title.split(\":\")\n",
    "            sum_wt += int(title_wt)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return sum_wt\n",
    "\n",
    "train_data[\"sum_wt\"] = train_data.progress_apply(get_sum_wt, axis = 1)\n",
    "test_data[\"sum_wt\"] = test_data.progress_apply(get_sum_wt, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Count variables\n",
    "def wcount(p):\n",
    "    return p.count(',')+1\n",
    "\n",
    "train_data['title_count'] = train_data['titles'].map(wcount)\n",
    "train_data['genres_count'] = train_data['genres'].map(wcount)\n",
    "train_data['cities_count'] = train_data['cities'].map(wcount)\n",
    "train_data['tod_count'] = train_data['tod'].map(wcount)\n",
    "train_data['dow_count'] = train_data['dow'].map(wcount)\n",
    "\n",
    "test_data['title_count'] = test_data['titles'].map(wcount)\n",
    "test_data['genres_count'] = test_data['genres'].map(wcount)\n",
    "test_data['cities_count'] = test_data['cities'].map(wcount)\n",
    "test_data['tod_count'] = test_data['tod'].map(wcount)\n",
    "test_data['dow_count'] = test_data['dow'].map(wcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Doubtful about how to utilize cities -- too many cities to one-hot encode\n",
    "train_data.drop(['cities','dow','genres','titles','tod'], inplace=True, axis=1)\n",
    "test_data.drop(['cities','dow','genres','titles','tod'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_data.csv\", index = False)\n",
    "test_data.to_csv(\"test_data.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
